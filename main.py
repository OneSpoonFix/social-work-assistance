import streamlit as st
import google.generativeai as genai

# --- 1. é…ç½®å¤§è„‘ (è¯·å¡«å…¥ä½ åœ¨ Google AI Studio è·å–çš„ Key) ---
# å®é™…ä¸Šçº¿æ—¶ä¸èƒ½è¿™æ ·æ˜æ–‡å†™ Keyï¼Œä½†åœ¨è‡ªå·±ç”µè„‘ä¸Šæµ‹è¯•æ²¡é—®é¢˜
genai.configure(api_key="ä½ çš„API_KEY_ç²˜è´´åœ¨è¿™é‡Œ") 

# é€‰æ‹©æ¨¡å‹ï¼ŒGemini-1.5-flash å…è´¹ä¸”é€Ÿåº¦å¿«ï¼Œé€‚åˆåš Demo
model = genai.GenerativeModel('gemini-1.5-flash')

# --- 2. é¡µé¢åŸºç¡€è®¾ç½® ---
st.set_page_config(page_title="ç¤¾å·¥AI Copilot", layout="wide", page_icon="ğŸ§¡")

st.title("ğŸ§¡ ç¤¾å·¥æ•°å­—åŒ–å…¨èƒ½å·¥ä½œå° (Demoç‰ˆ)")
st.markdown("---")

# --- 3. ä¾§è¾¹æ å¯¼èˆª ---
st.sidebar.header("åŠŸèƒ½å¯¼èˆª")
function_mode = st.sidebar.radio(
    "è¯·é€‰æ‹©ä½ éœ€è¦çš„åŠŸèƒ½ï¼š",
    ("ğŸ“ æ™ºèƒ½æ–‡ä¹¦ç”Ÿæˆ", "ğŸ—£ï¸ ä¸ªæ¡ˆè®°å½•æ•´ç†", "ğŸ§  æ”¿ç­–æ³•è§„å’¨è¯¢")
)

st.sidebar.info("è¿™æ˜¯ä¸€ä¸ªä¾æ‰˜äº Gemini æ¨¡å‹çš„ç¤¾å·¥è¡Œä¸šåº”ç”¨åŸå‹ã€‚")

# --- 4. æ ¸å¿ƒåŠŸèƒ½é€»è¾‘ ---

# === åŠŸèƒ½ A: æ–‡ä¹¦ç”Ÿæˆ ===
if function_mode == "ğŸ“ æ™ºèƒ½æ–‡ä¹¦ç”Ÿæˆ":
    st.subheader("ğŸ“ ç¤¾å·¥æ´»åŠ¨æ–‡ä¹¦ä¸€é”®ç”Ÿæˆ")
    col1, col2 = st.columns([1, 1])
    
    with col1:
        st.info("è¯·è¾“å…¥ç¢ç‰‡åŒ–çš„æ´»åŠ¨ä¿¡æ¯ï¼š")
        input_text = st.text_area("ä¾‹å¦‚ï¼šä»Šå¤©åœ¨ç¤¾åŒºæäº†åŒ…é¥ºå­æ´»åŠ¨ï¼Œæ¥äº†30ä¸ªè€äººï¼Œå¾ˆçƒ­é—¹ã€‚", height=200)
        style = st.selectbox("é€‰æ‹©ç›®æ ‡æ–‡ä½“", ["æ­£å¼æ–°é—»é€šç¨¿", "é¡¹ç›®æœˆæŠ¥æ±‡æŠ¥", "æ„Ÿæ€§æœ‹å‹åœˆæ–‡æ¡ˆ"])
        generate_btn = st.button("å¼€å§‹ç”Ÿæˆæ–‡ä¹¦")

    with col2:
        if generate_btn and input_text:
            with st.spinner('AI æ­£åœ¨åƒè€ç¤¾å·¥ä¸€æ ·æ€è€ƒå’Œå†™ä½œ...'):
                # æç¤ºè¯å·¥ç¨‹ (Prompt Engineering)
                prompt = f"""
                ä½ æ˜¯ä¸€åèµ„æ·±çš„ä¸­å›½ç¤¾å·¥æœºæ„è¡Œæ”¿äººå‘˜ã€‚è¯·æ ¹æ®ä»¥ä¸‹ç¢ç‰‡ä¿¡æ¯ï¼Œå†™ä¸€ç¯‡{style}ã€‚
                è¦æ±‚ï¼šè¯­è¨€ä¸“ä¸šã€ç¬¦åˆæ”¿åºœè´­ä¹°æœåŠ¡çš„è¦æ±‚ã€é€»è¾‘æ¸…æ™°ã€ç”¨è¯ç²¾å‡†ã€‚
                
                ç¢ç‰‡ä¿¡æ¯ï¼š{input_text}
                """
                response = model.generate_content(prompt)
                st.success("ç”Ÿæˆå®Œæˆï¼")
                st.markdown(response.text)

# === åŠŸèƒ½ B: ä¸ªæ¡ˆè®°å½• ===
elif function_mode == "ğŸ—£ï¸ ä¸ªæ¡ˆè®°å½•æ•´ç†":
    st.subheader("ğŸ—£ï¸ ä¸ªæ¡ˆæ¢è®¿è®°å½•åŠ©æ‰‹ (SOAPæ ¼å¼)")
    st.warning("ç¤¾å·¥åªéœ€è¦å£è¯­åŒ–è¾“å…¥æ¢è®¿è¿‡ç¨‹ï¼ŒAI è‡ªåŠ¨æ•´ç†ä¸ºä¸“ä¸šæ¡£æ¡ˆã€‚")
    
    raw_case = st.text_area("è¯·è¾“å…¥æ¢è®¿è¿‡ç¨‹ï¼ˆæ”¯æŒè¯­éŸ³è½¬æ–‡å­—åçš„æ–‡æœ¬ï¼‰ï¼š", 
                            "ä¾‹å¦‚ï¼šä»Šå¤©å»çœ‹äº†å¼ å¤§çˆ·ï¼Œä»–æ°”è‰²ä¸å¤ªå¥½ï¼Œè¯´æœ€è¿‘è¯åƒå®Œäº†æ²¡é’±ä¹°ã€‚æˆ‘çœ‹äº†ä¸‹å†°ç®±é‡Œä¹Ÿæ²¡èœäº†ã€‚æˆ‘è§‰å¾—ä»–å¯èƒ½éœ€è¦ç”³è¯·ä¸´æ—¶æ•‘åŠ©ã€‚æˆ‘æ‰“ç®—ä¸‹å‘¨å¸¦ç‚¹ç±³æ²¹è¿‡æ¥ï¼Œé¡ºä¾¿å¸®ä»–å¡«ä¸ªè¡¨ã€‚",
                            height=150)
    
    if st.button("æ•´ç†ä¸º SOAP è®°å½•"):
        with st.spinner('æ­£åœ¨åˆ†æä¸ªæ¡ˆè¦ç´ ...'):
            prompt = f"""
            ä½ æ˜¯ä¸€åä¸“ä¸šçš„ç¤¾å·¥ç£å¯¼ã€‚è¯·å°†ä»¥ä¸‹å£è¯­åŒ–çš„æ¢è®¿è®°å½•æ•´ç†ä¸ºæ ‡å‡†çš„ SOAP æ ¼å¼ã€‚
            S (ä¸»è§‚èµ„æ–™): æœåŠ¡å¯¹è±¡è¯´äº†ä»€ä¹ˆ
            O (å®¢è§‚èµ„æ–™): ç¤¾å·¥çœ‹åˆ°äº†ä»€ä¹ˆ
            A (è¯„ä¼°): ç¤¾å·¥çš„ä¸“ä¸šé¢„ä¼°
            P (è®¡åˆ’): ä¸‹ä¸€æ­¥åšä»€ä¹ˆ
            
            åŸå§‹è®°å½•ï¼š{raw_case}
            """
            response = model.generate_content(prompt)
            st.markdown(response.text)

# === åŠŸèƒ½ C: æ”¿ç­–å’¨è¯¢ ===
elif function_mode == "ğŸ§  æ”¿ç­–æ³•è§„å’¨è¯¢":
    st.subheader("ğŸ§  ç¤¾å·¥æ”¿ç­–æ™ºå›Š")
    
    # ç®€å•çš„ RAG æ¨¡æ‹Ÿï¼šè®©ç”¨æˆ·å…ˆç²˜è´´ä¸€æ®µæ”¿ç­–ï¼Œæˆ–è€…å‡è®¾ AI å·²ç»çŸ¥é“é€šç”¨æ”¿ç­–
    # åœ¨çœŸæ­£çš„äº§å“ä¸­ï¼Œè¿™é‡Œä¼šè¿æ¥æœ¬åœ°çŸ¥è¯†åº“
    policy_context = st.text_area("åœ¨æ­¤ç²˜è´´ç›¸å…³çš„æ”¿ç­–æ–‡ä»¶å†…å®¹ï¼ˆæ¨¡æ‹ŸçŸ¥è¯†åº“ï¼‰ï¼š", 
                                  "ä¾‹å¦‚ç²˜è´´ã€Šç¤¾ä¼šæ•‘åŠ©æš‚è¡ŒåŠæ³•ã€‹çš„å…¶ä¸­å‡ æ¡...", height=100)
    question = st.text_input("è¯·è¾“å…¥å…·ä½“çš„æ”¿ç­–ç–‘é—®ï¼š", "ä¾‹å¦‚ï¼šä½ä¿æˆ·æœ‰ä¸€å°ä»·å€¼5000å…ƒçš„ç”µè„‘ï¼Œæ˜¯å¦ä¼šå½±å“èµ„æ ¼ï¼Ÿ")
    
    if st.button("å’¨è¯¢ AI"):
        if not policy_context:
            st.error("Demoé˜¶æ®µï¼Œè¯·å…ˆåœ¨ä¸Šæ¡†ç²˜è´´ä¸€ç‚¹æ”¿ç­–æ–‡æœ¬ä½œä¸ºä¾æ®ã€‚")
        else:
            with st.spinner('AI æ­£åœ¨æ¯”å¯¹æ”¿ç­–æ¡æ¬¾...'):
                prompt = f"""
                ä½ æ˜¯ä¸€åç²¾é€šæ°‘æ”¿æ”¿ç­–çš„ç¤¾å·¥ä¸“å®¶ã€‚è¯·æ ¹æ®ä»¥ä¸‹æä¾›çš„æ”¿ç­–æ–‡æœ¬ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚
                å¦‚æœæ”¿ç­–æ–‡æœ¬ä¸­æ²¡æœ‰æåˆ°ï¼Œè¯·æ˜ç¡®å‘ŠçŸ¥ã€‚
                
                æ”¿ç­–ä¾æ®ï¼š{policy_context}
                
                ç”¨æˆ·é—®é¢˜ï¼š{question}
                """
                response = model.generate_content(prompt)
                st.markdown(response.text)